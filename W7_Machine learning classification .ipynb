{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff8ee9a1",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "## The Scikit Learn module\n",
    "\n",
    "The [scikit learn](https://scikit-learn.org/stable/) module is an open source module dedicated to implementing machine learning methods in python. It is the tool we will use for the next few weeks to explore these methods and apply them to some data.\n",
    "\n",
    "There are particular sections of the module dedicated to supervised and unsupervised machine learning tasks (recall these are where we have training examples and where we do not respectively). Here we are going to focus on supervised classification methods, that is, given training data classified into two classes (denoted 1 and 0), we want to use that data to construct a way to classify new data points based on that information.\n",
    "\n",
    "Firstly we are going to need to import some modules and functions to get started (we'll particularly take sub-modules connected to nearest neighbours and decision trees):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeeb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as skl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.neighbors as nei\n",
    "import sklearn.tree as tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed92db59",
   "metadata": {},
   "source": [
    "## First KNN example\n",
    "\n",
    "The first example we will work with is a synthetic dataset, made as it just has two features, which means we can plot the data points within the feature space more easily to get a handle on what's going on.\n",
    "\n",
    "Our dataset comes split in two parts `synth.tr.csv` and `synth.te.csv`, the first one containing our training data and the second our test data. Both therefore have labels, but recall we don't use the labels in the test set to build our model, just to compare with the predictions of our classifier to see how well we do.\n",
    "\n",
    "First let's load in the training dataset and have a look at it. Here is a scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbdf089",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data = pd.read_csv('synth.tr.csv')\n",
    "print(class_data.head())\n",
    "\n",
    "sns.scatterplot(data=class_data, x='xs', y='ys', hue='yc')\n",
    "plt.title('Scatter plot - coloured by class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3be9bb",
   "metadata": {},
   "source": [
    "Next we want to make a K nearest neighbour classifier based on this training data. To do that we start a classifier model, specifying K and the distance metric we will use (here we specify K=3, and normal Euclidean distance).\n",
    "\n",
    "We can predict a value of the class label for a made up data point - here we try the point (0,1) which looks like it should definitely be a 1 since it is in the middle of lots of orange points in the plot above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86d7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_class = nei.KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_class.fit(class_data[['xs','ys']],class_data['yc'])\n",
    "\n",
    "print(knn_class.predict([[0,1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5191a4ce",
   "metadata": {},
   "source": [
    "Don't worry about the warning we get from the last line - this is just saying we passed in data without heading names within a dataframe - and the training data was in a dataframe - so just warning us of the mismatch.\n",
    "\n",
    "Note that we have two methods associated with our classifier (denoted by the . notation to get to them). One is the `fit()` method that we pass in our data to. The pattern is the data points - here simply two columns of our dataframe, and then the associated label, here contained in another column of our dataframe. The second method `predict()` is used to apply our classifier to a new data point - we can give it a data point and ask what class the classifier gives as an output.\n",
    "\n",
    "So far so good then. We have a classifier, and we can test it out on a data point and it gives a classification. The next step is to look at our test data and see if we can begin to qunatify how well our classifier has done.\n",
    "\n",
    "First we can load in and have a look at the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ca10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('synth.te.csv')\n",
    "\n",
    "sns.scatterplot(data=test_data, x=\"xs\", y=\"ys\", color='green')\n",
    "plt.title(\"Scatter plot of test data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e2c7d",
   "metadata": {},
   "source": [
    "These are all of the data points in the test dataset. We then have to classify them by using our classifier above. It will find the nearest three points in our training dataset to each point here, and let them vote on the class for the point. With 3 neighbours selected there cannot be a draw.\n",
    "\n",
    "We can use the `predict()` method again here, this time passing in all of the data points within our test dataset. The next line creates a new column of the dataframe which we call 'class'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e88da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['class'] = knn_class.predict(test_data[['xs','ys']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d5ba9",
   "metadata": {},
   "source": [
    "We can look at the results of this classification. Here is the test dataset coloured according to the predicted class of each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994f8846",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=test_data, x=\"xs\", y=\"ys\",hue='class')\n",
    "plt.title(\"Scatter plot - test data coloured by class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1712c",
   "metadata": {},
   "source": [
    "We could also overlay on the plot all of the training data. Here we do that using triangular markers for the training data.\n",
    "\n",
    "You can look to see the closest 3 triangles to each circle - they are the ones which voted on that classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe73aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=class_data, x=\"xs\", y=\"ys\", hue=\"yc\",marker='^',legend=None)\n",
    "sns.scatterplot(data=test_data, x=\"xs\", y=\"ys\",hue='class')\n",
    "plt.title(\"Scatter plot - test data coloured by class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7804e8",
   "metadata": {},
   "source": [
    "## Assessing the classifier\n",
    "\n",
    "Looking at our test dataset we have two columns now which contain the real class of our data points 'yc', and the predicted class 'class'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78b8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99199ff8",
   "metadata": {},
   "source": [
    "Note that we can't see much from just the top of the dataframe. But if we look through the dataframe we can find locations where the values in these two columns don't match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d267f909",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data[test_data['yc']!=test_data['class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205182a",
   "metadata": {},
   "source": [
    "Note we have made both types of errors here, places where we have predicted a 1 but the real answer was a 0 - a False Positive. And also places where we precited a 0 but the real answer was 1 a False Negative.\n",
    "\n",
    "We can summarise all of the True/False Positive/Negatives in a confusion matrix. We can also look at the balanced accuracy and F scores (look back at the slides to see the definitions of each of these). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb30c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(skl.metrics.confusion_matrix(y_true=test_data['yc'],y_pred=test_data['class']))\n",
    "print(skl.metrics.balanced_accuracy_score(y_true=test_data['yc'],y_pred=test_data['class']))\n",
    "print(skl.metrics.f1_score(y_true=test_data['yc'],y_pred=test_data['class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e02359f",
   "metadata": {},
   "source": [
    "We can see we do a pretty good job, the majority of points are well classified. \n",
    "\n",
    "Let's compare to another model to see if we can do better - let's try KNN for the case K=5. Here we fit that model, predict the classes on the test dataset and compute our scores again just as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8022e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_class = nei.KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n",
    "knn_class.fit(class_data[['xs','ys']],class_data['yc'])\n",
    "test_data['class'] = knn_class.predict(test_data[['xs','ys']])\n",
    "\n",
    "print(skl.metrics.confusion_matrix(y_true=test_data['yc'],y_pred=test_data['class']))\n",
    "print(skl.metrics.balanced_accuracy_score(y_true=test_data['yc'],y_pred=test_data['class']))\n",
    "print(skl.metrics.f1_score(y_true=test_data['yc'],y_pred=test_data['class']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a360a1f1",
   "metadata": {},
   "source": [
    "So by all of these metrics the K=5 classifier appears to be a bit better than the K=3. \n",
    "\n",
    "## Second example\n",
    "\n",
    "The second data example is derived from the paper:\n",
    "Smith, J. W., Everhart, J. E., Dickson, W. C., Knowler, W. C. and Johannes, R. S. (1988) Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications in Medical Care (Washington, 1988), ed. R. A. Greenes, pp. 261â€“265. Los Alamitos, CA: IEEE Computer Society Press.\n",
    "\n",
    "This data contains measurements of various health indicators for use as a predictor for whether the study participants would go on to develop diabetes. The final column gives the true outcome for what happened to each participant.\n",
    "\n",
    "We can load in the data. Note there are more columns in this data - so the feature space is now 8-dimensional, which means we cannot simply visualise it all now. We will just look at a cross-section of the feature space and show the sixth column against the second column to get a small sense of how the feature space looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1ced4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_data = pd.read_csv('pima-indians-diabetes.csv')\n",
    "print(diabetes_data.head())\n",
    "print(diabetes_data.keys())\n",
    "sns.scatterplot(data=diabetes_data, x='glu', y='bmi', hue='class')\n",
    "plt.title(\"Scatter plot - coloured by class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d454ed",
   "metadata": {},
   "source": [
    "We can see some separation of the different classes, but of course we are missing the other directions in the feature space in our plot, so we can't tell whether those which merge together in the middle in our plot might separate out more if we look at other planes of the data.\n",
    "\n",
    "In this data set all of the labelled data is clumped in together in one file. So we need to split it ourselves into a training set and a test set. We can use a function in scikit learn to do this for us. \n",
    "\n",
    "Note the form of the following line. The function outputs data points for the train and test portions, and separately the classes for the train and test data points - usually called X and y respectively. In the input of the function we need to give the columns of data which make up our feature space, and the column with our labels. We also need to specify what fraction of the data we want to be used as a test set (usually we want to retain most of the data to do training with). Here we specify a third of the data to be our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c57922",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = skl.model_selection.train_test_split(diabetes_data[['npreg', 'glu', 'bp', 'skin', 'ins', 'bmi', 'ped', 'age']],diabetes_data['class'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27898297",
   "metadata": {},
   "source": [
    "Next we can use the `fit()` method to fit our KNN classifier for K=3. Then use the `predict()` method on our test data to obtain predicted classes for each data point in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_class = nei.KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_class.fit(X_train,y_train)\n",
    "y_predict=knn_class.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee3db06",
   "metadata": {},
   "source": [
    "Now we have both the real classes (contained in `y_test`) and the predicted classes (contained in `y_predict`) we can use these to obtain our various metrics to determine how well our classifier performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b08e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix: ',skl.metrics.confusion_matrix(y_test,y_predict))\n",
    "print('Precision: ',skl.metrics.precision_score(y_test,y_predict))\n",
    "print('Recall: ',skl.metrics.recall_score(y_test,y_predict))\n",
    "print('Balanced accuracy: ',skl.metrics.balanced_accuracy_score(y_test,y_predict))\n",
    "print('F1 score: ',skl.metrics.f1_score(y_true=y_test,y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c06f63",
   "metadata": {},
   "source": [
    "We can also look at the difference between the true and predicted classes in our slice of the feature space. Here is what they look like - you can see at least a few points which are different across the two plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6b17a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X_test, x='glu', y='bmi', hue=y_test)\n",
    "plt.title(\"Scatter plot - coloured by class - true class\")\n",
    "plt.show()\n",
    "sns.scatterplot(data=X_test, x='glu', y='bmi', hue=y_predict)\n",
    "plt.title(\"Scatter plot - coloured by class - predicted class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6d25b",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "We can also fit a decision tree classifier to the same data. The nice thing about the scikit learn module is that the `fit()` and `predict()` methods work in a reasonably standard way so fitting a new classifier model is pretty straightforward and follows a similar pattern.\n",
    "\n",
    "To do it we make a new decision tree classifier, use the `fit()` method with our training data, and use the `predict()` method with our test data - all in pretty similar fashion to the way we did this for the KNN case above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57125d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_class = tree.DecisionTreeClassifier()\n",
    "dt_class.fit(X_train,y_train)\n",
    "y_predict = dt_class.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42b6616",
   "metadata": {},
   "source": [
    "Now we have the true and predicted classes again, we can go ahead and find all of the metrics which detail how well the classifier has worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf0ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix: ',skl.metrics.confusion_matrix(y_test,y_predict))\n",
    "print('Precision: ',skl.metrics.precision_score(y_test,y_predict))\n",
    "print('Recall: ',skl.metrics.recall_score(y_test,y_predict))\n",
    "print('Balanced accuracy: ',skl.metrics.balanced_accuracy_score(y_test,y_predict))\n",
    "print('F1 score: ',skl.metrics.f1_score(y_true=y_test,y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfad442",
   "metadata": {},
   "source": [
    "Comparing to the KNN classifier above it looks like this does generally worse.\n",
    "\n",
    "Once again we can plot our cross section of the data showing the real and predited classes - again we can see some differences as we would expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49738065",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=X_test, x='glu', y='bmi', hue=y_test)\n",
    "plt.title(\"Scatter plot - coloured by class - true class\")\n",
    "plt.show()\n",
    "sns.scatterplot(data=X_test, x='glu', y='bmi', hue=y_predict)\n",
    "plt.title(\"Scatter plot - coloured by class - predicted class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2011a10f",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Here is a new dataset that contains 4 columns in the relevant dataframe. The first 3 columns represent the features, the fourth is the real class of each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e240070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "operation_data = pd.read_csv('haberman.csv')\n",
    "\n",
    "print(operation_data.head())\n",
    "print(operation_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddd91f8",
   "metadata": {},
   "source": [
    "1) Split the data up into a training and test dataset, use 50% of the data in each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b1481d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17ba2db7",
   "metadata": {},
   "source": [
    "2) Fit a decision tree classfier to the data and output the balanced accuracy and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d94ce25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a45ac622",
   "metadata": {},
   "source": [
    "3) Fit the KNN classifier with K=3 to the data and output the balanced accuracy and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d5911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7c6bef2",
   "metadata": {},
   "source": [
    "4) Which method did best? What's your justification for that conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccbb642",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
