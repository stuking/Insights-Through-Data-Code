{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a44915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages/modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6748f5",
   "metadata": {},
   "source": [
    "# Binary Linear Regression (Logistic Regression)\n",
    "\n",
    "We have discussed one Linear Regression model in this course, that is Normal Linear Regression model in which the response variable is Normally distributed. Another important and widely used type of linear model is Binary Linear Regression or \"Logistic Regression\" in which the response variable is a Binary (dichotomous)  variable. In such a model the response variable takes only two states for each member of the sample, for example it could be yes/no, 0/1, positive/negative, disease/no_disease, absent/present, etc. You see that such a variable can't be normally distributed so we need a different type of linear model to model it. \n",
    "\n",
    "This notebook is a brief introduction on how to fit a Logistic Regression model and assess it. Logistic Regression is also considered a classification technique in machine learning as it enables us to predict a binary response variable, therefore categorising the (current/future) observations in two categories of the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92396ff5",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "\"This dataset is a stratified random sample from all active customers (at the end of June 2006) of a European financial services company. The dependent variable in this dataset is the churn behaviour of the customers in the period from July 1st until December 31th 2006. Here a churned customer is defined as someone who closed all their bank accounts with the company. All predictor variables are standardized. This dataset is a small subset of the dataset used by Benoit and Van den Poel (2013). The dataset is structured as a dataframe with 400 observations and 5 variables. \" Source: https://www.rdocumentation.org/packages/bayesQR/versions/2.3/topics/Churn\n",
    "\n",
    "The data frame has the following components:\n",
    "\n",
    "    churn : churn (yes=1 / no=0)\n",
    "    gender : gender of the customer (male=1 / female=0)\n",
    "    Social_Class_Score : social class of the customer\n",
    "    lor : length of relationship with the customer\n",
    "    recency : number of days since last purchase\n",
    "    \n",
    "We aim to model the response variable `churn` (which only takes 0 or 1 values) to explain and predict the customer's behaviour in closing/keeping their bank accounts with this company using the provided predictors in the dataset. \n",
    "\n",
    "Let's look at the dataset and summary of its variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc44ce52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>churn</th>\n",
       "      <th>gender</th>\n",
       "      <th>Social_Class_Score</th>\n",
       "      <th>lor</th>\n",
       "      <th>recency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4632</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.115675</td>\n",
       "      <td>-1.089221</td>\n",
       "      <td>-0.721322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9695</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.313425</td>\n",
       "      <td>1.182983</td>\n",
       "      <td>3.634435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14160</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.325439</td>\n",
       "      <td>-0.846156</td>\n",
       "      <td>-0.427582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11016</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.966515</td>\n",
       "      <td>0.086942</td>\n",
       "      <td>-0.535672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.454692</td>\n",
       "      <td>-1.166642</td>\n",
       "      <td>-0.672640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>761</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.617163</td>\n",
       "      <td>1.077655</td>\n",
       "      <td>0.878567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>16865</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.104424</td>\n",
       "      <td>-1.273770</td>\n",
       "      <td>-0.869016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>6225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.407781</td>\n",
       "      <td>-0.426195</td>\n",
       "      <td>0.684666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>6187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.278528</td>\n",
       "      <td>0.818836</td>\n",
       "      <td>1.428091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>11348</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.245691</td>\n",
       "      <td>0.691452</td>\n",
       "      <td>1.346405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  churn  gender  Social_Class_Score       lor   recency\n",
       "0          4632      0       1           -0.115675 -1.089221 -0.721322\n",
       "1          9695      0       0           -0.313425  1.182983  3.634435\n",
       "2         14160      0       1           -1.325439 -0.846156 -0.427582\n",
       "3         11016      0       1            1.966515  0.086942 -0.535672\n",
       "4         16286      0       1            1.454692 -1.166642 -0.672640\n",
       "..          ...    ...     ...                 ...       ...       ...\n",
       "395         761      1       1            0.617163  1.077655  0.878567\n",
       "396       16865      1       0           -1.104424 -1.273770 -0.869016\n",
       "397        6225      1       0            0.407781 -0.426195  0.684666\n",
       "398        6187      1       1           -0.278528  0.818836  1.428091\n",
       "399       11348      1       1            2.245691  0.691452  1.346405\n",
       "\n",
       "[400 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churndata = pd.read_csv(\"Churn-BayesQR-R.csv\")\n",
    "churndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46315d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>churn</th>\n",
       "      <th>gender</th>\n",
       "      <th>Social_Class_Score</th>\n",
       "      <th>lor</th>\n",
       "      <th>recency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8635.430000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>-0.052156</td>\n",
       "      <td>-0.034370</td>\n",
       "      <td>0.144549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4773.621405</td>\n",
       "      <td>0.500626</td>\n",
       "      <td>0.500601</td>\n",
       "      <td>1.083829</td>\n",
       "      <td>0.952936</td>\n",
       "      <td>1.103133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.803510</td>\n",
       "      <td>-1.273770</td>\n",
       "      <td>-0.870666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4876.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.688568</td>\n",
       "      <td>-0.828377</td>\n",
       "      <td>-0.645824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8636.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.045881</td>\n",
       "      <td>-0.152072</td>\n",
       "      <td>-0.265036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12554.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.550277</td>\n",
       "      <td>0.544826</td>\n",
       "      <td>0.571214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16908.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.432190</td>\n",
       "      <td>3.738312</td>\n",
       "      <td>5.928242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0       churn      gender  Social_Class_Score         lor  \\\n",
       "count    400.000000  400.000000  400.000000          400.000000  400.000000   \n",
       "mean    8635.430000    0.500000    0.495000           -0.052156   -0.034370   \n",
       "std     4773.621405    0.500626    0.500601            1.083829    0.952936   \n",
       "min       20.000000    0.000000    0.000000           -4.803510   -1.273770   \n",
       "25%     4876.000000    0.000000    0.000000           -0.688568   -0.828377   \n",
       "50%     8636.000000    0.500000    0.000000           -0.045881   -0.152072   \n",
       "75%    12554.750000    1.000000    1.000000            0.550277    0.544826   \n",
       "max    16908.000000    1.000000    1.000000            3.432190    3.738312   \n",
       "\n",
       "          recency  \n",
       "count  400.000000  \n",
       "mean     0.144549  \n",
       "std      1.103133  \n",
       "min     -0.870666  \n",
       "25%     -0.645824  \n",
       "50%     -0.265036  \n",
       "75%      0.571214  \n",
       "max      5.928242  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churndata.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0952c47",
   "metadata": {},
   "source": [
    "We make a `crosstab` table to see how many 0/1 there are in churn variable. In this case the number of each category's observations are equal but it is just a coincidence and the response doen't have to be like that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea529c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>churn</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  count\n",
       "churn       \n",
       "0        200\n",
       "1        200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(index=churndata['churn'], columns='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb58bebb",
   "metadata": {},
   "source": [
    "We can still fit a normal linear regression to this response variable and check the model's output. However, we know this is not correct and the model is not reliable because the response variable is not approximately normally distributed.\n",
    "\n",
    "The predictor variable `gender` is a categorical variable, meaning that the two values it takes, 0 and 1, are not representing integer values of 0 and 1, but categories. So we wrap it in an uppercase C and parentheses () to indicate it is a categorical variable. It is common to describe categorical variables like this. For example, if you have a variable showing blood groups as A, B, AB and O and you want to include it in a model, whether the categories are shown with A, B, AB and O or 0,1,2,3, you can use the C(blood_type) in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6dfc55dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>churn</td>      <th>  R-squared:         </th> <td>   0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   8.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 17 Oct 2022</td> <th>  Prob (F-statistic):</th> <td>1.52e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>16:54:11</td>     <th>  Log-Likelihood:    </th> <td> -273.91</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   557.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   395</td>      <th>  BIC:               </th> <td>   577.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>    0.4865</td> <td>    0.035</td> <td>   14.022</td> <td> 0.000</td> <td>    0.418</td> <td>    0.555</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(gender)[T.1]</th>     <td>   -0.0146</td> <td>    0.049</td> <td>   -0.301</td> <td> 0.764</td> <td>   -0.110</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recency</th>            <td>    0.1127</td> <td>    0.024</td> <td>    4.657</td> <td> 0.000</td> <td>    0.065</td> <td>    0.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_Class_Score</th> <td>    0.0051</td> <td>    0.022</td> <td>    0.228</td> <td> 0.820</td> <td>   -0.039</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lor</th>                <td>   -0.1388</td> <td>    0.028</td> <td>   -4.954</td> <td> 0.000</td> <td>   -0.194</td> <td>   -0.084</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2222.388</td> <th>  Durbin-Watson:     </th> <td>   0.173</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>  49.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.060</td>  <th>  Prob(JB):          </th> <td>1.42e-11</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 1.273</td>  <th>  Cond. No.          </th> <td>    2.92</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  churn   R-squared:                       0.079\n",
       "Model:                            OLS   Adj. R-squared:                  0.069\n",
       "Method:                 Least Squares   F-statistic:                     8.444\n",
       "Date:                Mon, 17 Oct 2022   Prob (F-statistic):           1.52e-06\n",
       "Time:                        16:54:11   Log-Likelihood:                -273.91\n",
       "No. Observations:                 400   AIC:                             557.8\n",
       "Df Residuals:                     395   BIC:                             577.8\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept              0.4865      0.035     14.022      0.000       0.418       0.555\n",
       "C(gender)[T.1]        -0.0146      0.049     -0.301      0.764      -0.110       0.081\n",
       "recency                0.1127      0.024      4.657      0.000       0.065       0.160\n",
       "Social_Class_Score     0.0051      0.022      0.228      0.820      -0.039       0.049\n",
       "lor                   -0.1388      0.028     -4.954      0.000      -0.194      -0.084\n",
       "==============================================================================\n",
       "Omnibus:                     2222.388   Durbin-Watson:                   0.173\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               49.961\n",
       "Skew:                          -0.060   Prob(JB):                     1.42e-11\n",
       "Kurtosis:                       1.273   Cond. No.                         2.92\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting a normal linear regression model\n",
    "nor_reg = smf.ols(\"churn ~ recency + C(gender) + Social_Class_Score + lor\", data=churndata).fit()\n",
    "nor_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f061e",
   "metadata": {},
   "source": [
    "The coefficeint of `C(gender)[T.1]` corresponds to level 1 of variable Gender which is \"male\". In case of having categorical predictors, the model is formulated separately for all different levels of that variable. Here we have:\n",
    "\n",
    "For male customrs:    `churn = 0.49 - 0.01 + 0.11*recency + 0.01*Social_Class_Score - 0.14*lor`\n",
    "\n",
    "For female customrs:  `churn = 0.49 + 0.11*recency + 0.01*Social_Class_Score - 0.14*lor`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caa1adc",
   "metadata": {},
   "source": [
    "Just to show how a normal linear model is not appropriate in this case, we plot the response variable against one of the predictors, recency, with a normal linear regression line. You see the response only takes 0,1 and the line is not explaining that very well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cadebad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(x=\"recency\", y=\"churn\", data=churndata)\n",
    "plt.axline(xy1=(0, nor_reg.params[0]), slope=nor_reg.params[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c065c3",
   "metadata": {},
   "source": [
    "### Binary linear regression (logistic regression)\n",
    "\n",
    "We can fit a model to this data that technically is still a linear model but we need to specify that the reponse variable is from a Binary (0/1) distribution. Therefore, we use the `logit` function from `statsmodels.formula.api`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef355077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.651007\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>churn</td>      <th>  No. Observations:  </th>  <td>   400</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   395</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 12 Oct 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.06080</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>15:42:45</td>     <th>  Log-Likelihood:    </th> <td> -260.40</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -277.26</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>8.537e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>          <td>   -0.0827</td> <td>    0.151</td> <td>   -0.547</td> <td> 0.585</td> <td>   -0.379</td> <td>    0.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(gender)[T.1]</th>     <td>   -0.0651</td> <td>    0.210</td> <td>   -0.311</td> <td> 0.756</td> <td>   -0.476</td> <td>    0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>recency</th>            <td>    0.5085</td> <td>    0.114</td> <td>    4.462</td> <td> 0.000</td> <td>    0.285</td> <td>    0.732</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Social_Class_Score</th> <td>    0.0185</td> <td>    0.096</td> <td>    0.193</td> <td> 0.847</td> <td>   -0.169</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lor</th>                <td>   -0.6434</td> <td>    0.140</td> <td>   -4.607</td> <td> 0.000</td> <td>   -0.917</td> <td>   -0.370</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}       &      churn       & \\textbf{  No. Observations:  } &      400    \\\\\n",
       "\\textbf{Model:}               &      Logit       & \\textbf{  Df Residuals:      } &      395    \\\\\n",
       "\\textbf{Method:}              &       MLE        & \\textbf{  Df Model:          } &        4    \\\\\n",
       "\\textbf{Date:}                & Thu, 12 Oct 2023 & \\textbf{  Pseudo R-squ.:     } &  0.06080    \\\\\n",
       "\\textbf{Time:}                &     15:42:45     & \\textbf{  Log-Likelihood:    } &   -260.40   \\\\\n",
       "\\textbf{converged:}           &       True       & \\textbf{  LL-Null:           } &   -277.26   \\\\\n",
       "\\textbf{Covariance Type:}     &    nonrobust     & \\textbf{  LLR p-value:       } & 8.537e-07   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                              & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}            &      -0.0827  &        0.151     &    -0.547  &         0.585        &       -0.379    &        0.214     \\\\\n",
       "\\textbf{C(gender)[T.1]}       &      -0.0651  &        0.210     &    -0.311  &         0.756        &       -0.476    &        0.346     \\\\\n",
       "\\textbf{recency}              &       0.5085  &        0.114     &     4.462  &         0.000        &        0.285    &        0.732     \\\\\n",
       "\\textbf{Social\\_Class\\_Score} &       0.0185  &        0.096     &     0.193  &         0.847        &       -0.169    &        0.206     \\\\\n",
       "\\textbf{lor}                  &      -0.6434  &        0.140     &    -4.607  &         0.000        &       -0.917    &       -0.370     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  churn   No. Observations:                  400\n",
       "Model:                          Logit   Df Residuals:                      395\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Thu, 12 Oct 2023   Pseudo R-squ.:                 0.06080\n",
       "Time:                        15:42:45   Log-Likelihood:                -260.40\n",
       "converged:                       True   LL-Null:                       -277.26\n",
       "Covariance Type:            nonrobust   LLR p-value:                 8.537e-07\n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "Intercept             -0.0827      0.151     -0.547      0.585      -0.379       0.214\n",
       "C(gender)[T.1]        -0.0651      0.210     -0.311      0.756      -0.476       0.346\n",
       "recency                0.5085      0.114      4.462      0.000       0.285       0.732\n",
       "Social_Class_Score     0.0185      0.096      0.193      0.847      -0.169       0.206\n",
       "lor                   -0.6434      0.140     -4.607      0.000      -0.917      -0.370\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting a logistic regression model\n",
    "log_reg = smf.logit(\"churn ~ recency + C(gender) + Social_Class_Score + lor\", data=churndata).fit()\n",
    "log_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a96e4c",
   "metadata": {},
   "source": [
    "Summary of the model is similar to that of a normal regression. The predictors `recency` and `lor` have significant coefficients in the model. However, the interpretation of the coefficients is different from that of a normal linear model because a [logistic function](https://en.wikipedia.org/wiki/Logistic_function) is involved in this model to fit a curve to the response variable based on the predictors. \n",
    "\n",
    "The general formula of a logistic model with two predictors is: log(P(Y=1)/P(Y=0)) = a + b_1* x_1 + b_2* X_2\n",
    "\n",
    "log(P(Y=1)/P(Y=0)) is the log-odds or logit of the probability that the dependent variable Y takes on the value 1 (success or the event of interest) relative to the probability that it takes on the value 0 (failure or the complement of the event of interest). P(Y=1)/P(Y=0) is the odds of Y taking place.\n",
    "\n",
    "\n",
    "In a logistic regression, we need to calculate the [Odds Ratio](https://en.wikipedia.org/wiki/Odds_ratio) of predictors by taking `exp` of their coefficients. Then:\n",
    "\n",
    "- OR=1 implies that a one-unit change in X_i has no effect on the odds of the event occurring. In other words, X_i has no influence on the event's probability.\n",
    "- OR>1  suggests that a one-unit increase in X_i is associated with an increase in the odds of the event occurring. The larger the OR, the greater the impact. (With one unit increase in X_i, the odds of the response occuring multiplies by exp(b_i), and in this case b_i is positive).\n",
    "- OR<1  indicates that a one-unit increase in X_i is associated with a decrease in the odds of the event occurring. The closer the OR is to 0, the stronger the negative impact. (With one unit increase in X_i, the odds of the response occuring multiplies by exp(b_i), and in this case b_i is negative.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa3bba70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          OR  Lower CI  Upper CI\n",
      "Intercept           0.920644  0.684444  1.238355\n",
      "C(gender)[T.1]      0.936948  0.621377  1.412783\n",
      "recency             1.662831  1.329933  2.079058\n",
      "Social_Class_Score  1.018678  0.844187  1.229236\n",
      "lor                 0.525493  0.399649  0.690964\n"
     ]
    }
   ],
   "source": [
    "# calculating Odds Ratios and their confidence intervals\n",
    "coefficients = pd.DataFrame(\n",
    "    {\n",
    "        \"OR\": log_reg.params,\n",
    "        \"Lower CI\": log_reg.conf_int()[0],\n",
    "        \"Upper CI\": log_reg.conf_int()[1],\n",
    "    }\n",
    ")\n",
    "odds_ratios = np.exp(coefficients)\n",
    "print(odds_ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c51fcd",
   "metadata": {},
   "source": [
    "The predictors `recency` and `lor` have significant coefficients in this model. OR of `recency` (number of days since last purchase) is larger than 1, it means that increasing this predictor increases the odds of response being equal to 1 or customer churning (closing their accounts). OR of `lor` (length of relationship with the customer) is smaller than 1, it means that increasing this predictor decreases the odds of response being equal to 1 or customer churning (closing their accounts). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a6705b",
   "metadata": {},
   "source": [
    "## Model assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f2ff8",
   "metadata": {},
   "source": [
    "The model assessment methods we discussed for normal linear regression, don't usually apply here. Instead we explore how good our model predicts the binary (0/1) response variable. We will use the `predict` function, which predicts the probability of the response being equal to 1. Then if this probability is larger than 0.5, the prediction is 1 and if it is smaller than or equal to 0.5, the prediction is 0. This way we predict the response variable in 0 and 1. (It is possible to change the threshold of 0.5 to another value to maximise the prediction accuracy of the model, using [Roc curves](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4fb539",
   "metadata": {},
   "source": [
    "We apply `predict` to all the  observations, and report howmany 0s have been predicted as 0 or 1, and howmany 1s have been predicted as 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25e2a900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_response  predicted_response\n",
      "0                0.0                   102\n",
      "                 1.0                    98\n",
      "1                0.0                    55\n",
      "                 1.0                   145\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "actual_response = churndata[\"churn\"]\n",
    "predicted_response = np.round(log_reg.predict()) # <=0.5 -> 0\n",
    "outcomes = pd.DataFrame({\"actual_response\": actual_response, \"predicted_response\": predicted_response})\n",
    "print(outcomes.value_counts(sort=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea9e4a9",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "We can also calculate the Specificity, Sensitivity, False Positive and False Negative of the model's prediction. The function `pred_table` provides the frequencies we generated before, in a matrix, called a confusion matrix. This model has correctly predicted 62% of the response variable observations, and performs better in predicting true positives than true negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4def65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[102.  98.]\n",
      " [ 55. 145.]]\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = log_reg.pred_table()\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b478c978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[102.0, 145.0, 55.0, 98.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN = conf_matrix[0,0] #true negatives\n",
    "TP = conf_matrix[1,1] #true positives\n",
    "FN = conf_matrix[1,0] #false negatives\n",
    "FP = conf_matrix[0,1] #false positive\n",
    "[TN, TP, FN, FP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b4134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.6175\n",
      "sensitivity:  0.725\n",
      "specificity:  0.51\n"
     ]
    }
   ],
   "source": [
    "accuracy = (TN + TP) / (TN + TP + FN + FP) # accuracy of model's prediction\n",
    "sensitivity = TP / (FN + TP) # sensitivity of the model-the proportion of actual positive cases that were correctly identified by the model.\n",
    "specificity = TN / (TN + FP) # specificity of the model-the proportion of actual negative cases that were correctly identified by the model\n",
    "print(\"accuracy: \", accuracy)\n",
    "print(\"sensitivity: \", sensitivity) \n",
    "print(\"specificity: \", specificity) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de6ce49",
   "metadata": {},
   "source": [
    "### Train and Test data and Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8564e973",
   "metadata": {},
   "source": [
    "Here we fitted a model to all the 400 observations and predicted the same 400 observations to assess the prediction power of the model. However, in practice it is common to split the data into two groups of Training and Testing. For example 80% of the dataset could be randomly selected as the Training part and the other 20% could be the Testing part. Then the model is built only using the training data. Afterwards, the model is used for predicting the response variable in the testing part of the dataset. This way the model predicts values that were not fed into it in the model-making step and therefore provides a better measurement of how good its prediction power is.  \n",
    "\n",
    "This process can be further improved in k-fold [Cross Validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics). \"In k-fold cross-validation, the original sample is randomly partitioned into k equal-sized subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k âˆ’ 1 subsamples are used as training data. The cross-validation process is then repeated k times, with each of the k subsamples used exactly once as the validation data. \""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
